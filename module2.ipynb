{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод Apriori ассоциативного анализа\n",
    "\n",
    "Написанного Ю Мочизуки (Yu Mochizuki)\n",
    "Устанавливаем\n",
    "\n",
    "```\n",
    "pip install apyori\n",
    "copy apyori.py into your project.\n",
    "python setup.py install\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Данные https://www.kaggle.com/datasets/devchauhan1/market-basket-optimisationcsv\n",
    "dataset = pd.read_csv(\"./data/Market_Basket_Optimisation.csv\", header=None)\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очистка данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fillna(method=\"ffill\", axis=1, inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "\n",
    "# создадим из них матрицу\n",
    "transactions = []\n",
    "for i in range(0, 7501):\n",
    "    transactions.append([str(dataset.values[i, j]) for j in range(0, 20)])\n",
    "\"\"\" \n",
    "и обучимся правилам. Обратите внимание, что пороговые значения мы выбираем сами в зависимости от того,\n",
    "насколько \"сильные\" правила мы хотим получить\n",
    "min_support -- минимальный support для правил (dtype = float).\n",
    "min_confidence -- минимальное значение confidence для правил (dtype = float)\n",
    "min_lift -- минимальный lift (dtype = float)\n",
    "max_length -- максимальная длина itemset (вспоминаем про k-itemset)  (dtype = integer) \n",
    "\"\"\"\n",
    "result = list(\n",
    "    apriori(\n",
    "        transactions, min_support=0.003, min_confidence=0.2, min_lift=4, min_length=2\n",
    "    )\n",
    ")\n",
    "apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "from io import StringIO\n",
    "from apyori import dump_as_json\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "\n",
    "output = []\n",
    "for RelationRecord in result:\n",
    "    o = StringIO()\n",
    "    dump_as_json(RelationRecord, o)\n",
    "    output.append(json.loads(o.getvalue()))\n",
    "df = pd.DataFrame(output)\n",
    "df.sort_values(by=[\"support\"], ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результат\n",
    "\n",
    "Видим сочетания:\n",
    "\n",
    "- оливковое масло, макароны из цельнозерновой муки [olive oil, whole wheat pasta],\n",
    "- говяжий фарш, зелень и перец, спагетти [ground beef, herb & pepper, spaghetti],\n",
    "- эскалоп, макароны [escalope, pasta]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теоретическая часть\n",
    "\n",
    "- https://www.kdnuggets.com/2016/04/association-rules-apriori-algorithm-tutorial.html\n",
    "- https://stackabuse.com/association-rule-mining-via-apriori-algorithm-in-python/\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эффективный вариант Apriori с использованием сокращения хэшей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned itemset [2, 5]\n",
      "\n",
      "ЧАСТЫЕ НАБОРЫ ЭЛЕМЕНТОВ (минимальное количество поддержки = 3)\n",
      "{1}\n",
      "{2}\n",
      "{3}\n",
      "{5}\n",
      "{1, 2}\n",
      "{1, 3}\n",
      "{1, 5}\n",
      "{2, 3}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Эффективный вариант Apriori с использованием сокращения хэшей\n",
    "\"\"\"\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "class hashTable:\n",
    "    def __init__(self, hash_table_size):\n",
    "        self.hash_table = [0] * hash_table_size\n",
    "\n",
    "    def add_itemset(self, itemset):\n",
    "        hash_index = (itemset[0] * 10 + itemset[1]) % 7\n",
    "        self.hash_table[hash_index] += 1\n",
    "\n",
    "    def get_itemset_count(self, itemset):\n",
    "        hash_index = (itemset[0] * 10 + itemset[1]) % 7\n",
    "        return self.hash_table[hash_index]\n",
    "\n",
    "\n",
    "def generateCandidateItemsets(level_k, level_frequent_itemsets):\n",
    "    \"\"\"Генерация и сокращение наборов элементов-кандидатов для следующего уровня с использованием часто используемых наборов элементов текущего уровня.\n",
    "    @ Параметры\n",
    "    ----------\n",
    "    level_k : целое число\n",
    "            Текущий номер уровня\n",
    "\n",
    "    level_frequent_itemsets : список списков\n",
    "            Список частых наборов предметов текущего уровня\n",
    "    @ Возвращает\n",
    "    -------\n",
    "    список списков\n",
    "            Наборы-кандидаты следующего уровня\n",
    "    \"\"\"\n",
    "    n_frequent_itemsets = len(level_frequent_itemsets)\n",
    "    candidate_frequent_itemsets = []\n",
    "    for i in range(n_frequent_itemsets):\n",
    "        j = i + 1\n",
    "        while (j < n_frequent_itemsets) and (\n",
    "            level_frequent_itemsets[i][: level_k - 1]\n",
    "            == level_frequent_itemsets[j][: level_k - 1]\n",
    "        ):\n",
    "            candidate_itemset = (\n",
    "                level_frequent_itemsets[i][: level_k - 1]\n",
    "                + [level_frequent_itemsets[i][level_k - 1]]\n",
    "                + [level_frequent_itemsets[j][level_k - 1]]\n",
    "            )\n",
    "            candidate_itemset_pass = False\n",
    "\n",
    "            if level_k == 1:\n",
    "                candidate_itemset_pass = True\n",
    "\n",
    "            elif (level_k == 2) and (candidate_itemset[-2:] in level_frequent_itemsets):\n",
    "                candidate_itemset_pass = True\n",
    "\n",
    "            elif all(\n",
    "                (list(_) + candidate_itemset[-2:]) in level_frequent_itemsets\n",
    "                for _ in combinations(candidate_itemset[:-2], level_k - 2)\n",
    "            ):\n",
    "                candidate_itemset_pass = True\n",
    "\n",
    "            if candidate_itemset_pass:\n",
    "                candidate_frequent_itemsets.append(candidate_itemset)\n",
    "\n",
    "            j += 1\n",
    "\n",
    "    return candidate_frequent_itemsets\n",
    "\n",
    "\n",
    "def aprioriAlgorithm(transactions, min_support_count):\n",
    "    \"\"\"Извлечение часто встречающихся наборов элементов из транзакций с использованием априорного алгоритма\n",
    "    @ Параметры\n",
    "    ----------\n",
    "    транзакции : список наборов\n",
    "            Список транзакций\n",
    "\n",
    "    min_support_count : целое число\n",
    "            Минимальное количество поддержки для набора элементов, которое считается частым\n",
    "    @ Возвращает\n",
    "    -------\n",
    "    список наборов\n",
    "             Список частых наборов элементов, извлеченных из транзакций\n",
    "    \"\"\"\n",
    "\n",
    "    # Извлечь список элементов в транзакциях\n",
    "    items = set()\n",
    "    for transaction in transactions:\n",
    "        items.update(transaction)\n",
    "    items = sorted(list(items))\n",
    "\n",
    "    # Список частых наборов в транзакции\n",
    "    frequent_itemsets = []\n",
    "\n",
    "    level_k = 1  # Текущий номер уровня\n",
    "\n",
    "    level_frequent_itemsets = []  # Level 0: частые наборы предметов\n",
    "    candidate_frequent_itemsets = [\n",
    "        [item] for item in items\n",
    "    ]  # Level 1: наборы элементов-кандидатов\n",
    "\n",
    "    # Инициализировать хеш-таблицу\n",
    "    hash_tb = hashTable(7)\n",
    "\n",
    "    while candidate_frequent_itemsets:\n",
    "        # Подсчитаем поддержку всех возможных часто используемых наборов элементов и удалим транзакции, используя сокращение транзакций\n",
    "        candidate_freq_itemsets_cnts = [0] * len(candidate_frequent_itemsets)\n",
    "\n",
    "        for transaction in transactions:\n",
    "            # добавить количество наборов элементов размера 2 в хеш-таблицу\n",
    "            if level_k == 1:\n",
    "                for itemset in combinations(transaction, 2):\n",
    "                    hash_tb.add_itemset(itemset)\n",
    "\n",
    "            for i, itemset in enumerate(candidate_frequent_itemsets):\n",
    "                if all(_item in transaction for _item in itemset):\n",
    "                    candidate_freq_itemsets_cnts[i] += 1\n",
    "\n",
    "        # Сгенерируем часто встречающиеся наборы элементов уровня k путем сокращения нечастых наборов элементов\n",
    "        level_frequent_itemsets = [\n",
    "            itemset\n",
    "            for itemset, support in zip(\n",
    "                candidate_frequent_itemsets, candidate_freq_itemsets_cnts\n",
    "            )\n",
    "            if support >= min_support_count\n",
    "        ]\n",
    "        frequent_itemsets.extend(\n",
    "            [\n",
    "                set(level_frequent_itemset)\n",
    "                for level_frequent_itemset in level_frequent_itemsets\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Сгенерируйте кандидатов Ck+1 из Ck (используя генерацию и обрезку)\n",
    "        candidate_frequent_itemsets = generateCandidateItemsets(\n",
    "            level_k, level_frequent_itemsets\n",
    "        )\n",
    "        level_k += 1\n",
    "\n",
    "        # Обрежем C_2, используя хеш-таблицу, сгенерированную во время L_1\n",
    "        if level_k == 2:\n",
    "            for itemset in candidate_frequent_itemsets:\n",
    "                if hash_tb.get_itemset_count(itemset) < min_support_count:\n",
    "                    print(\"Pruned itemset\", itemset)\n",
    "                    candidate_frequent_itemsets.remove(itemset)\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "\n",
    "\"\"\" Load the standard market basket dataset from datasets module \"\"\"\n",
    "\"\"\" \n",
    "Загрузим данные\n",
    "def load_market_basket():\n",
    "        import pandas as pd\n",
    "        # Данные https://www.kaggle.com/datasets/devchauhan1/market-basket-optimisationcsv\n",
    "        dataset = pd.read_csv('./data/market_basket.csv', header = None)\n",
    "        # Preprocessing the dataset\n",
    "        transactions = []\n",
    "        for index, data in dataset.iterrows():\n",
    "                transaction = [len(el) for el in pd.Series.tolist(data[~pd.isnull(data)])]\n",
    "                transactions.append(set(transaction))\n",
    "        return transactions\n",
    "\n",
    "transactions = load_market_basket()\n",
    "min_support_count = 100\n",
    "verbose = False \"\"\"\n",
    "\n",
    "\"\"\" Пример данных, предложенный - Arun K. Pujari \"\"\"\n",
    "transactions = [\n",
    "    {1, 2, 5},\n",
    "    {2, 4},\n",
    "    {2, 3},\n",
    "    {1, 2, 4},\n",
    "    {1, 3},\n",
    "    {2, 3},\n",
    "    {1, 3},\n",
    "    {1, 2, 3, 5},\n",
    "    {1, 2, 3},\n",
    "    {1, 2},\n",
    "    {1, 3, 5},\n",
    "]\n",
    "\n",
    "min_support_count = 3\n",
    "\n",
    "# Сгенерируйте список всех часто используемых наборов элементов с помощью сокращения транзакций Apriori\n",
    "frequent_itemsets = aprioriAlgorithm(transactions, min_support_count)\n",
    "\n",
    "print(\n",
    "    \"\\nЧАСТЫЕ НАБОРЫ ЭЛЕМЕНТОВ (минимальное количество поддержки = {})\".format(\n",
    "        min_support_count\n",
    "    )\n",
    ")\n",
    "for frequent_itemset in frequent_itemsets:\n",
    "    print(frequent_itemset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
