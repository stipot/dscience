{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластерный анализ финансовых рынков\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установка ta-lib\n",
    "\n",
    "### Для Windows\n",
    "\n",
    "- Инструкции: https://github.com/afnhsn/TA-Lib_x64\n",
    "- Скачать \"ta-lib x64.zip\" https://github.com/afnhsn/TA-Lib_x64. Распаковать zip файл в C:\\ta-lib\n",
    "- Скачать Visual C++ build tools 2022: https://aka.ms/vs/17/release/vs_buildtools.exe\n",
    "- Установить Visual C++ build tools: https://stackoverflow.com/a/54136652/10997732\n",
    "- Установить ta-lib: pip install ta-lib\n",
    "\n",
    "### На Linux блок ниже\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем ta-lib и другие модули\n",
    "# Этот блок необходим только для Unix систем\n",
    "\"\"\" \n",
    "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "!tar xvzf ta-lib-0.4.0-src.tar.gz\n",
    "%cd ta-lib/\n",
    "!./configure --prefix=/usr\n",
    "!make\n",
    "!make install\n",
    "!pip install TA-Lib \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install hmmlearn\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем библиотеки\n",
    "import numpy as np\n",
    "import talib\n",
    "from hmmlearn import hmm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "\n",
    "# Для доступа к данным на Google drive\n",
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "symbol = \"FTMUSDT\"\n",
    "fraction = 0\n",
    "period = \"1m\"\n",
    "candles = pd.read_csv(rf\"./data/candles_{symbol}_{period}.csv\").iloc[fraction:]\n",
    "candles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Generate synthetic data\n",
    "# Assuming 'candles' is a DataFrame containing your OHLCV data\n",
    "data = candles[[\"Unnamed: 0\", \"close\", \"high\", \"low\"]].rename(\n",
    "    columns={\"Unnamed: 0\": \"timestamp\", \"close\": \"price\"}\n",
    ")\n",
    "data[\"timestamp\"] = data[\"timestamp\"].str[:19]\n",
    "data.set_index(\"timestamp\", inplace=True)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data.resample(\"30m\").apply({\"price\": \"ohlc\", \"high\": \"max\", \"low\": \"min\"})\n",
    "data.columns = [\"\".join(col).strip() for col in data.columns.values]\n",
    "data = data * 1000\n",
    "\n",
    "# Calculate Parabolic SAR\n",
    "\n",
    "data[\"sar\"] = talib.SAR(\n",
    "    data[\"price\"].values, data[\"price\"].values, acceleration=0.02, maximum=0.2\n",
    ")\n",
    "\n",
    "# Additional Features\n",
    "data[\"price_diff\"] = data[\"price\"].diff()\n",
    "data[\"sar_diff\"] = data[\"sar\"].diff()\n",
    "data[\"momentum\"] = data[\"price\"].diff(3)\n",
    "data[\"volatility\"] = data[\"price\"].rolling(window=5).std()\n",
    "data[\"distance_to_sar\"] = data[\"price\"] - data[\"sar\"]\n",
    "data[\"rolling_max\"] = data[\"price\"].rolling(window=5).max()\n",
    "data[\"rolling_min\"] = data[\"price\"].rolling(window=5).min()\n",
    "data[\"price_over_sar_ratio\"] = data[\"price\"] / data[\"sar\"]\n",
    "\n",
    "# Drop NaN rows created by feature engineering\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Prepare features for HMM\n",
    "features = data[\n",
    "    [\n",
    "        \"price_diff\",\n",
    "        \"sar_diff\",\n",
    "        \"momentum\",\n",
    "        \"volatility\",\n",
    "        \"distance_to_sar\",\n",
    "        \"rolling_max\",\n",
    "        \"rolling_min\",\n",
    "        \"price_over_sar_ratio\",\n",
    "    ]\n",
    "].values\n",
    "\n",
    "# Create and train HMM\n",
    "model = hmm.GaussianHMM(n_components=3, covariance_type=\"full\", n_iter=100)\n",
    "model.fit(features)\n",
    "\n",
    "# Predict hidden states\n",
    "data[\"hidden_state\"] = model.predict(features)\n",
    "\n",
    "# Interpret hidden states as reversal types\n",
    "state_means = np.array(\n",
    "    [np.mean(features[data[\"hidden_state\"] == i], axis=0) for i in range(3)]\n",
    ")\n",
    "sorted_states = np.argsort(state_means[:, 0])\n",
    "\n",
    "data[\"reversal_type\"] = \"Neutral\"\n",
    "data.loc[data[\"hidden_state\"] == sorted_states[0], \"reversal_type\"] = \"Down\"\n",
    "data.loc[data[\"hidden_state\"] == sorted_states[2], \"reversal_type\"] = \"Up\"\n",
    "\n",
    "# Trading simulation\n",
    "initial_balance = 100000\n",
    "balance = initial_balance\n",
    "stock_quantity = 0\n",
    "trade_log = []\n",
    "\n",
    "# Create a list to track balance over time and a list to track buy dates\n",
    "data[\"balance\"] = initial_balance\n",
    "buy_dates = []\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    if row[\"reversal_type\"] == \"Up\" and stock_quantity == 0:\n",
    "        stock_quantity = balance // row[\"price\"]\n",
    "        balance -= stock_quantity * row[\"price\"]\n",
    "        data.at[i, \"balance\"] = balance\n",
    "        buy_dates.append(i)\n",
    "        trade_log.append(f\"Buy at {row['price']} on {i}, Balance: {balance}\")\n",
    "    elif row[\"reversal_type\"] == \"Down\" and stock_quantity > 0:\n",
    "        balance += stock_quantity * row[\"price\"]\n",
    "        stock_quantity = 0\n",
    "        data.at[i, \"balance\"] = balance\n",
    "        trade_log.append(f\"Sell at {row['price']} on {i}, Balance: {balance}\")\n",
    "\n",
    "# Remaining stocks are sold at the last price\n",
    "if stock_quantity > 0:\n",
    "    balance += stock_quantity * data[\"price\"].iloc[-1]\n",
    "    data.at[data.index[-1], \"balance\"] = balance\n",
    "    trade_log.append(\n",
    "        f\"Sell at {data['price'].iloc[-1]} on {data.index[-1]}, Balance: {balance}\"\n",
    "    )\n",
    "\n",
    "# Calculate final portfolio value\n",
    "final_portfolio_value = balance\n",
    "\n",
    "print(f\"Final Portfolio Value: {final_portfolio_value}\")\n",
    "print(\"\\nTrading log:\")\n",
    "for log in trade_log:\n",
    "    print(log)\n",
    "\n",
    "# ... [Plotting section] ...\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles=(\n",
    "        \"Price and Parabolic SAR\",\n",
    "        \"Balance Over Time (after Buy operations)\",\n",
    "    ),\n",
    "    row_heights=[0.7, 0.3],\n",
    ")\n",
    "\n",
    "# Add Price, SAR and Reversal Type data to the first subplot\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=data.index, y=data[\"price\"], mode=\"lines\", name=\"Price\"), row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=data.index,\n",
    "        y=data[\"sar\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Parabolic SAR\",\n",
    "        line=dict(dash=\"dash\"),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=data.index,\n",
    "        y=data[\"price\"],\n",
    "        mode=\"markers\",\n",
    "        name=\"Reversal Type\",\n",
    "        marker=dict(color=data[\"reversal_type\"].apply(lambda x: colors[x]), size=5),\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Filter balance data for only buy_dates and subtract initial_balance\n",
    "buy_balance = data.loc[buy_dates, \"balance\"] - initial_balance\n",
    "\n",
    "# Add filtered balance data to the second subplot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=buy_balance.index,\n",
    "        y=buy_balance,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Balance After Buy\",\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Update and show figure\n",
    "fig.update_layout(title_text=\"Price, Parabolic SAR, and Balance Over Time\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from hmmlearn import hmm\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import sys\n",
    "\n",
    "\n",
    "def zigzag(s, threshold=1.0):\n",
    "    zz = pd.Series(index=s.index)\n",
    "    last_zz = s.iloc[0]\n",
    "    zz.iloc[0] = last_zz\n",
    "    trend = None\n",
    "\n",
    "    for i in range(1, len(s)):\n",
    "        price = s.iloc[i]\n",
    "        prev = last_zz\n",
    "        move = price - prev\n",
    "        pct_move = abs(move) / prev\n",
    "\n",
    "        if pct_move >= threshold:\n",
    "            if move > 0 and trend != 1:\n",
    "                last_zz = price\n",
    "                zz.iloc[i] = price\n",
    "                trend = 1\n",
    "            elif move < 0 and trend != -1:\n",
    "                last_zz = price\n",
    "                zz.iloc[i] = price\n",
    "                trend = -1\n",
    "\n",
    "    return zz\n",
    "\n",
    "\n",
    "# Generate synthetic data\n",
    "data = candles[[\"Unnamed: 0\", \"close\", \"high\", \"low\"]].rename(\n",
    "    columns={\"Unnamed: 0\": \"timestamp\", \"close\": \"price\"}\n",
    ")\n",
    "data[\"timestamp\"] = data[\"timestamp\"].str[:19]\n",
    "data.set_index(\"timestamp\", inplace=True)\n",
    "data = data * 1000\n",
    "\n",
    "# Calculate Parabolic SAR\n",
    "data[\"sar\"] = talib.SAR(\n",
    "    data[\"price\"].values, data[\"price\"].values, acceleration=0.02, maximum=0.2\n",
    ")\n",
    "\n",
    "# Add zigzag indicator (simplified for example)\n",
    "threshold = 1.0  # Define your own threshold\n",
    "data[\"zigzag\"] = zigzag(data[\"price\"], threshold=0.01)\n",
    "\n",
    "\n",
    "# Create features\n",
    "data[\"sar_position\"] = np.where(data[\"sar\"] > data[\"price\"], 1, -1)\n",
    "data[\"sar_position_change\"] = data[\"sar_position\"].diff()\n",
    "feature_list = [\"sar_position_change\"]  # Add more features if needed\n",
    "\n",
    "# Drop NaN\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Evaluate clustering with different features\n",
    "best_score = -1\n",
    "best_features = None\n",
    "\n",
    "for feature_combo in combinations(feature_list, 1):  # Single feature for illustration\n",
    "    features = data[list(feature_combo)].values.reshape(-1, 1)\n",
    "    model = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", n_iter=100)\n",
    "    model.fit(features)\n",
    "    hidden_states = model.predict(features)\n",
    "\n",
    "    # Check if there are at least two unique hidden states\n",
    "    if len(set(hidden_states)) < 2:\n",
    "        print(\n",
    "            f\"Skipping feature set {feature_combo} due to insufficient unique hidden states.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        score = silhouette_score(features, hidden_states)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_features = feature_combo\n",
    "    except ValueError:\n",
    "        print(\n",
    "            f\"Cannot calculate silhouette score for feature set {feature_combo}. Skipping.\"\n",
    "        )\n",
    "\n",
    "# Check if we found any suitable feature set for clustering\n",
    "if best_features is None:\n",
    "    print(\"No suitable feature set found for clustering. Exiting.\")\n",
    "    sys.exit()\n",
    "print(best_features)\n",
    "# Train the final model with best features\n",
    "features = data[list(best_features)].values.reshape(-1, 1)\n",
    "model = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", n_iter=100)\n",
    "model.fit(features)\n",
    "data[\"hidden_state\"] = model.predict(features)\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add Price Line\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"price\"], mode=\"lines\", name=\"Price\"))\n",
    "\n",
    "# Add Zigzag points\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=data.index, y=data[\"zigzag\"], mode=\"markers\", name=\"Zigzag Extremes\")\n",
    ")\n",
    "\n",
    "# Add Candlestick\n",
    "fig.add_trace(\n",
    "    go.Candlestick(\n",
    "        x=data.index,\n",
    "        open=data[\"price\"],\n",
    "        high=data[\"high\"],\n",
    "        low=data[\"low\"],\n",
    "        close=data[\"price\"],\n",
    "        name=\"Candlestick\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add cluster points\n",
    "cluster_0 = data[data[\"hidden_state\"] == 0]\n",
    "cluster_1 = data[data[\"hidden_state\"] == 1]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cluster_0.index,\n",
    "        y=cluster_0[\"price\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=\"green\"),\n",
    "        name=\"Cluster 0\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cluster_1.index,\n",
    "        y=cluster_1[\"price\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=\"blue\"),\n",
    "        name=\"Cluster 1\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title=\"Price, Zigzag, and Clusters\",\n",
    "    xaxis_title=\"Timestamp\",\n",
    "    yaxis_title=\"Price\",\n",
    "    xaxis_rangeslider_visible=False,\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"Best feature set: {best_features}\")\n",
    "print(f\"Best silhouette score: {best_score}\")\n",
    "# Initialize variables for trading simulation\n",
    "initial_balance = 100000\n",
    "balance = initial_balance\n",
    "stock_quantity = 0\n",
    "buy_price = 0\n",
    "trade_log = []\n",
    "\n",
    "# Simulate trading based on clustering results\n",
    "for i in range(1, len(data)):\n",
    "    if data[\"hidden_state\"][i] != data[\"hidden_state\"][i - 1]:\n",
    "        if stock_quantity == 0:  # Buy\n",
    "            stock_quantity = balance // data[\"price\"][i]\n",
    "            balance -= stock_quantity * data[\"price\"][i]\n",
    "            buy_price = data[\"price\"][i]\n",
    "            trade_log.append(f\"Buy at {buy_price}, Balance: {balance}\")\n",
    "\n",
    "        else:  # Sell\n",
    "            balance += stock_quantity * data[\"price\"][i]\n",
    "            stock_quantity = 0\n",
    "            trade_log.append(f\"Sell at {data['price'][i]}, Balance: {balance}\")\n",
    "\n",
    "# Calculate final portfolio value\n",
    "final_portfolio_value = balance + stock_quantity * data[\"price\"].iloc[-1]\n",
    "print(\n",
    "    f\"Final Portfolio Value: {final_portfolio_value}, Total Trades: {len(trade_log)//2}\"\n",
    ")\n",
    "\n",
    "# Trading log\n",
    "\"\"\" for log in trade_log:\n",
    "    print(log) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from itertools import combinations\n",
    "import plotly.express as px\n",
    "\n",
    "# Assuming 'candles' is a DataFrame containing your OHLCV data\n",
    "data = candles[[\"Unnamed: 0\", \"close\", \"high\", \"low\"]].rename(\n",
    "    columns={\"Unnamed: 0\": \"timestamp\", \"close\": \"price\"}\n",
    ")\n",
    "data[\"timestamp\"] = data[\"timestamp\"].str[:19]\n",
    "data.set_index(\"timestamp\", inplace=True)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data.resample(\"1H\").apply({\"price\": \"ohlc\", \"high\": \"max\", \"low\": \"min\"})\n",
    "data.columns = [\"\".join(col).strip() for col in data.columns.values]\n",
    "\n",
    "# Calculate SAR\n",
    "data[\"sar\"] = talib.SAR(\n",
    "    data[\"price\"].values, data[\"price\"].values, acceleration=0.02, maximum=0.2\n",
    ")\n",
    "\n",
    "# Generate features\n",
    "data[\"sar_position\"] = np.where(data[\"sar\"] > data[\"price\"], 1, -1)\n",
    "data[\"sar_position_change\"] = data[\"sar_position\"].diff()\n",
    "data[\"sar_price_diff\"] = data[\"sar\"] - data[\"price\"]\n",
    "# Drop NaN rows\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Feature list and combinations\n",
    "feature_list = [\"sar\", \"sar_position\", \"sar_position_change\", \"sar_price_diff\"]\n",
    "feature_combinations = [\n",
    "    combo\n",
    "    for i in range(1, len(feature_list) + 1)\n",
    "    for combo in combinations(feature_list, i)\n",
    "]\n",
    "\n",
    "best_score = -1\n",
    "best_features = None\n",
    "\n",
    "# Evaluate each combination with KMeans and silhouette score\n",
    "steps = 0\n",
    "n_clusters = 2\n",
    "n_init = \"auto\"\n",
    "for feature_combo in feature_combinations:\n",
    "    # print(f\"Step: {steps} from {len(feature_combinations)}\")\n",
    "    steps += 1\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, random_state=0)\n",
    "    features = data[list(feature_combo)]\n",
    "    kmeans.fit(features)\n",
    "\n",
    "    clusters = kmeans.predict(features)\n",
    "    score = silhouette_score(features, clusters)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_features = feature_combo\n",
    "\n",
    "# Re-cluster with best features\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, random_state=0)\n",
    "features = data[list(best_features)]\n",
    "kmeans.fit(features)\n",
    "data[\"cluster\"] = kmeans.predict(features)\n",
    "\n",
    "# Plotly Visualization\n",
    "fig = px.scatter(\n",
    "    data.reset_index(),\n",
    "    x=\"timestamp\",\n",
    "    y=\"price\",\n",
    "    color=\"cluster\",\n",
    "    title=\"Cluster Identification\",\n",
    "    labels={\"cluster\": \"Cluster ID\"},\n",
    "    color_continuous_scale=[\"green\", \"red\", \"blue\"],\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Timestamp\", yaxis_title=\"Price\", coloraxis_showscale=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"Best feature set: {best_features}\")\n",
    "print(f\"Best silhouette score: {best_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
