{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение без учителя\n",
    "\n",
    "В задачах обучения без учителя у нас есть только входные данные x(i) без меток, и мы хотим, чтобы алгоритм нашел некоторую структуру в данных.\n",
    "\n",
    "Алгоритм кластеризации, такой как алгоритм k-средних, пытается сгруппировать данные в k «кластеров», которые имеют некоторое сходство.\n",
    "\n",
    "Примеры: анализ социальных сетей, организация компьютерных кластеров и анализ астрономических данных.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means\n",
    "Алгоритм кластеризации K-Means использует итеративное уточнение для получения окончательного результата. Входными данными алгоритма являются количество кластеров К и набор данных. Набор данных представляет собой набор функций для каждой точки данных. Алгоритмы начинаются с начальных оценок для К-центроидов, которые могут быть либо сгенерированы случайным образом, либо случайным образом выбраны из набора данных. Затем алгоритм повторяется между двумя шагами:\n",
    "\n",
    "1. Шаг присвоения данных:\n",
    "\n",
    "Каждый центроид определяет один из кластеров. На этом этапе каждой точке данных присваивается ее ближайший центр тяжести на основе квадрата евклидова расстояния. Более формально, если ci представляет собой набор центроидов в наборе C, то каждая точка данных x назначается кластеру на основе\n",
    "\n",
    "$$\\underset{c_i \\in C}{\\arg\\min} \\; dist(c_i,x)^2$$\n",
    "\n",
    "2. Шаг обновления Centroid:\n",
    "\n",
    "На этом этапе центроиды пересчитываются. Это делается путем получения среднего значения всех точек данных, назначенных кластеру этого центроида.\n",
    "\n",
    "$$c_i=\\frac{1}{|S_i|}\\sum_{x_i \\in S_i x_i}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "n_samples = 1500\n",
    "random_state = 1760\n",
    "X, y = make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit_predict(X)\n",
    "y_pred = kmeans.predict(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred)\n",
    "print(kmeans.score(X))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как выбрать количество кластеров\n",
    "\n",
    "Метод Elbow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(1,10):\n",
    "    kmeans = KMeans(n_clusters=i, n_init=\"auto\")\n",
    "    kmeans.fit_predict(X)\n",
    "    scores.append([i,kmeans.score(X)])\n",
    "display(scores)\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(pd.DataFrame(np.array(scores))[0],pd.DataFrame(np.array(scores))[1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Иерархическая (агломеративная) кластеризация\n",
    "\n",
    "- Изначально каждая точка сама является кластером.\n",
    "- Два ближайших кластера неоднократно объединяются в один.\n",
    "- Остановка, когда останется только один кластер.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "plt.title('Датасет iris')\n",
    "plt.xlabel('Длина дерева')\n",
    "plt.ylabel('Ширина дерева')\n",
    "plt.scatter(X[:, 0], X[:, 1], s=10, c=y, cmap='rainbow')\n",
    "\n",
    "Z = linkage(X, 'ward')\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Дендрограмма иерархической кластеризации')\n",
    "plt.xlabel('простой индекс')\n",
    "plt.ylabel('дистанция')\n",
    "\n",
    "dendrogram(Z, leaf_rotation=90., leaf_font_size=8.);\n",
    "plt.show();\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Дендрограмма иерархической кластеризации')\n",
    "plt.xlabel('простой индекс')\n",
    "plt.ylabel('дистанция')\n",
    "dendrogram(Z, leaf_rotation=90., leaf_font_size=8., truncate_mode='lastp');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример неприменимости Иерархической кластеризации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_circles\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "X, y = make_moons(1000, noise=.05)\n",
    "cl = AgglomerativeClustering(n_clusters=2).fit(X)\n",
    "ax[0].scatter(X[:, 0], X[:, 1], c=cl.labels_, s=10, cmap='rainbow');\n",
    "\n",
    "X, y = make_circles(1000, factor=.5, noise=.05)\n",
    "cl = AgglomerativeClustering(n_clusters=2).fit(X)\n",
    "ax[1].scatter(X[:, 0], X[:, 1], c=cl.labels_, s=10, cmap='rainbow');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Спектральна кластеризация\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_circles\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "X, y = make_moons(1000, noise=.05)\n",
    "cl = SpectralClustering(n_clusters=2, affinity='nearest_neighbors').fit(X)\n",
    "ax[0].scatter(X[:, 0], X[:, 1], c=cl.labels_, s=10, cmap='rainbow');\n",
    "\n",
    "X, y = make_circles(1000, factor=.5, noise=.05)\n",
    "cl = SpectralClustering(n_clusters=2, affinity='nearest_neighbors').fit(X)\n",
    "ax[1].scatter(X[:, 0], X[:, 1], c=cl.labels_, s=10, cmap='rainbow');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_circles\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "X, y = make_moons(1000, noise=.05)\n",
    "cl = DBSCAN(eps=0.1).fit(X)\n",
    "ax[0].scatter(X[:, 0], X[:, 1], c=cl.labels_, s=10, cmap='rainbow');\n",
    "\n",
    "X, y = make_circles(1000, factor=.5, noise=.05)\n",
    "cl = DBSCAN(eps=0.1).fit(X)\n",
    "ax[1].scatter(X[:, 0], X[:, 1], c=cl.labels_, s=10, cmap='rainbow');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# ============\n",
    "# Создание наборов данных. Мы выбираем размер достаточно большим, чтобы увидеть масштабируемость\n",
    "# алгоритмов, но не слишком большое, чтобы избежать слишком долгого времени выполнения\n",
    "# ============\n",
    "n_samples = 500\n",
    "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=0.05)\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=0.05)\n",
    "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
    "no_structure = np.random.rand(n_samples, 2), None\n",
    "\n",
    "# Анизотропно распределенные данные\n",
    "random_state = 170\n",
    "X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "X_aniso = np.dot(X, transformation)\n",
    "aniso = (X_aniso, y)\n",
    "\n",
    "# капли с разной дисперсией\n",
    "varied = datasets.make_blobs(\n",
    "    n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state\n",
    ")\n",
    "\n",
    "# ============\n",
    "# Настройте параметры кластера\n",
    "# ============\n",
    "plt.figure(figsize=(9 * 2 + 3, 13))\n",
    "plt.subplots_adjust(\n",
    "    left=0.02, right=0.98, bottom=0.001, top=0.95, wspace=0.05, hspace=0.01\n",
    ")\n",
    "\n",
    "plot_num = 1\n",
    "\n",
    "default_base = {\n",
    "    \"quantile\": 0.3,\n",
    "    \"eps\": 0.3,\n",
    "    \"damping\": 0.9,\n",
    "    \"preference\": -200,\n",
    "    \"n_neighbors\": 3,\n",
    "    \"n_clusters\": 3,\n",
    "    \"min_samples\": 7,\n",
    "    \"xi\": 0.05,\n",
    "    \"min_cluster_size\": 0.1,\n",
    "}\n",
    "\n",
    "datasets = [\n",
    "    (\n",
    "        noisy_circles,\n",
    "        {\n",
    "            \"damping\": 0.77,\n",
    "            \"preference\": -240,\n",
    "            \"quantile\": 0.2,\n",
    "            \"n_clusters\": 2,\n",
    "            \"min_samples\": 7,\n",
    "            \"xi\": 0.08,\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        noisy_moons,\n",
    "        {\n",
    "            \"damping\": 0.75,\n",
    "            \"preference\": -220,\n",
    "            \"n_clusters\": 2,\n",
    "            \"min_samples\": 7,\n",
    "            \"xi\": 0.1,\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        varied,\n",
    "        {\n",
    "            \"eps\": 0.18,\n",
    "            \"n_neighbors\": 2,\n",
    "            \"min_samples\": 7,\n",
    "            \"xi\": 0.01,\n",
    "            \"min_cluster_size\": 0.2,\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        aniso,\n",
    "        {\n",
    "            \"eps\": 0.15,\n",
    "            \"n_neighbors\": 2,\n",
    "            \"min_samples\": 7,\n",
    "            \"xi\": 0.1,\n",
    "            \"min_cluster_size\": 0.2,\n",
    "        },\n",
    "    ),\n",
    "    (blobs, {\"min_samples\": 7, \"xi\": 0.1, \"min_cluster_size\": 0.2}),\n",
    "    (no_structure, {}),\n",
    "]\n",
    "\n",
    "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
    "    # обновить параметры со значениями, специфичными для набора данных\n",
    "    params = default_base.copy()\n",
    "    params.update(algo_params)\n",
    "\n",
    "    X, y = dataset\n",
    "\n",
    "    # нормализовать набор данных для облегчения выбора параметров\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # estimate bandwidth for mean shift\n",
    "    bandwidth = cluster.estimate_bandwidth(X, quantile=params[\"quantile\"])\n",
    "\n",
    "    # матрица связности для структурированного Ward\n",
    "    connectivity = kneighbors_graph(\n",
    "        X, n_neighbors=params[\"n_neighbors\"], include_self=False\n",
    "    )\n",
    "    # обеспечить симметричную связность\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "    # ============\n",
    "    # Создание кластерных объектов\n",
    "    # ============\n",
    "    ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    two_means = cluster.MiniBatchKMeans(n_clusters=params[\"n_clusters\"], n_init=\"auto\")\n",
    "    ward = cluster.AgglomerativeClustering(\n",
    "        n_clusters=params[\"n_clusters\"], linkage=\"ward\", connectivity=connectivity\n",
    "    )\n",
    "    spectral = cluster.SpectralClustering(\n",
    "        n_clusters=params[\"n_clusters\"],\n",
    "        eigen_solver=\"arpack\",\n",
    "        affinity=\"nearest_neighbors\",\n",
    "    )\n",
    "    dbscan = cluster.DBSCAN(eps=params[\"eps\"])\n",
    "    optics = cluster.OPTICS(\n",
    "        min_samples=params[\"min_samples\"],\n",
    "        xi=params[\"xi\"],\n",
    "        min_cluster_size=params[\"min_cluster_size\"],\n",
    "    )\n",
    "    affinity_propagation = cluster.AffinityPropagation(\n",
    "        damping=params[\"damping\"], preference=params[\"preference\"], random_state=0\n",
    "    )\n",
    "    average_linkage = cluster.AgglomerativeClustering(\n",
    "        linkage=\"average\",\n",
    "        metric=\"cityblock\",\n",
    "        n_clusters=params[\"n_clusters\"],\n",
    "        connectivity=connectivity,\n",
    "    )\n",
    "    birch = cluster.Birch(n_clusters=params[\"n_clusters\"])\n",
    "    gmm = mixture.GaussianMixture(\n",
    "        n_components=params[\"n_clusters\"], covariance_type=\"full\"\n",
    "    )\n",
    "\n",
    "    clustering_algorithms = (\n",
    "        (\"MiniBatch\\nKMeans\", two_means),\n",
    "        (\"Affinity\\nPropagation\", affinity_propagation),\n",
    "        (\"MeanShift\", ms),\n",
    "        (\"Spectral\\nClustering\", spectral),\n",
    "        (\"Ward\", ward),\n",
    "        (\"Agglomerative\\nClustering\", average_linkage),\n",
    "        (\"DBSCAN\", dbscan),\n",
    "        (\"OPTICS\", optics),\n",
    "        (\"BIRCH\", birch),\n",
    "        (\"Gaussian\\nMixture\", gmm),\n",
    "    )\n",
    "\n",
    "    for name, algorithm in clustering_algorithms:\n",
    "        t0 = time.time()\n",
    "\n",
    "        # перехватить предупреждения, связанные с kneighbors_graph\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\",\n",
    "                message=\"the number of connected components of the \"\n",
    "                + \"connectivity matrix is [0-9]{1,2}\"\n",
    "                + \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "                category=UserWarning,\n",
    "            )\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\",\n",
    "                message=\"Graph is not fully connected, spectral embedding\"\n",
    "                + \" may not work as expected.\",\n",
    "                category=UserWarning,\n",
    "            )\n",
    "            algorithm.fit(X)\n",
    "\n",
    "        t1 = time.time()\n",
    "        if hasattr(algorithm, \"labels_\"):\n",
    "            y_pred = algorithm.labels_.astype(int)\n",
    "        else:\n",
    "            y_pred = algorithm.predict(X)\n",
    "\n",
    "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
    "        if i_dataset == 0:\n",
    "            plt.title(name, size=18)\n",
    "\n",
    "        colors = np.array(\n",
    "            list(\n",
    "                islice(\n",
    "                    cycle(\n",
    "                        [\n",
    "                            \"#377eb8\",\n",
    "                            \"#ff7f00\",\n",
    "                            \"#4daf4a\",\n",
    "                            \"#f781bf\",\n",
    "                            \"#a65628\",\n",
    "                            \"#984ea3\",\n",
    "                            \"#999999\",\n",
    "                            \"#e41a1c\",\n",
    "                            \"#dede00\",\n",
    "                        ]\n",
    "                    ),\n",
    "                    int(max(y_pred) + 1),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        # добавить черный цвет для выбросов (если есть)\n",
    "        colors = np.append(colors, [\"#000000\"])\n",
    "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
    "\n",
    "        plt.xlim(-2.5, 2.5)\n",
    "        plt.ylim(-2.5, 2.5)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.text(\n",
    "            0.99,\n",
    "            0.01,\n",
    "            (\"%.2fs\" % (t1 - t0)).lstrip(\"0\"),\n",
    "            transform=plt.gca().transAxes,\n",
    "            size=15,\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "        plot_num += 1\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
